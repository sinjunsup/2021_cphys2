{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825bb58f",
   "metadata": {},
   "source": [
    "## 1. fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "917634c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ca6b467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 위와 같은 모델을 클래스를 이용하여 작성\n",
    "class net(nn.Module): # nn.Module 상속(inheritance)\n",
    "    def __init__(self): # 초기값\n",
    "        super(net, self).__init__() # nn.Module의 함수를 model에서 사용 \n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x,start_dim=1)/255 # flatten\n",
    "        x = x.view(-1, 28*28).float()\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = nn.functional.softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "392e0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net()\n",
    "\n",
    "# loss and optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ea57b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini batch\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5676d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data):\n",
    "    model.train() # training\n",
    "    for X,y in data:\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "        \n",
    "        optimizer.zero_grad() # zero_grad(): 미분값 초기화\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c4d6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, criterion, optimizer, data):\n",
    "    model.eval() #evaluation\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    with torch.no_grad(): # no update\n",
    "        for X, y in data:\n",
    "            y_pred = model(X)\n",
    "            test_loss += criterion(y_pred, y)\n",
    "            \n",
    "            prediction = y_pred.max(1)[1] # max indices\n",
    "            corrects = (prediction == y)\n",
    "            accuracy += corrects.sum().float() / float( y.size(0) )\n",
    "    return test_loss, accuracy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e05f7fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= 158.18392944335938 accu= 87.80998229980469\n",
      "2 loss= 159.3319549560547 accu= 86.66999053955078\n",
      "4 loss= 158.4934539794922 accu= 87.6500015258789\n",
      "6 loss= 158.17405700683594 accu= 87.8899917602539\n",
      "8 loss= 157.72488403320312 accu= 88.31998443603516\n"
     ]
    }
   ],
   "source": [
    "nums_epoch = 10\n",
    "for epoch in range(nums_epoch):\n",
    "    train(model, criterion, optimizer, train_loader)\n",
    "    \n",
    "    if(epoch%2==0):\n",
    "        E, accu = evaluation(model, criterion, optimizer, test_loader)\n",
    "        print(epoch, \"loss=\", E.item(), \"accu=\", accu.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871b2af",
   "metadata": {},
   "source": [
    "## 2. 아래의 글을 읽고 500자 이내로 감상문을 작성하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ed969",
   "metadata": {},
   "outputs": [],
   "source": [
    "이 글에서 계속 주장하는 것은 고정관념을 깨야 한다. 이렇게 말하고 있는데 필자는 다르게 생각한다. \n",
    "우선 필자의 생각을 말하기 앞서 베이커 그룹과 알파폴드의 문제 접근 차이점이다. \n",
    "베이커 그룹은 다른 기술을 만드는 것에 초점을 두었다면 알파폴드는 기존의 기술을 찾는 쪽이었다.  \n",
    "비록 알파폴드가 승리했지만 이것이 알파폴드가 모든 면에서 이겼다고 보기는 어렵다.     \n",
    "오히려 새로운 기술을 발견한 베이커 그룹이 향후 ai 기술을 더 발전시킬지도 모르는 일이다. \n",
    "이것을 비유적으로 표현하면 연구는 검은 방을 밝히는 것이라면 ai는 밝은 방을 걷는 것이다.  \n",
    "즉 ai는 현재로서는 기술을 만드는 기술은 아니다. 새로운 기술을 찾는 것은 아직 인간의 영역이다. \n",
    "그렇기에 베이커 그룹은 실패했다고 볼 수 없다. \n",
    "결국 이 글에서 함정은 고정관념을 깨야 한다고 말하면서 어떻게 깨야 하는가를 말하고 있지 않다.\n",
    "단지 결과만 가지고 베이커 그룹의 노력이 물거품인양 보이게 만들 수 있는 것이다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
